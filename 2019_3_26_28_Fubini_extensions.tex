\section{2019 03 26 -- 28}

\subsection{Kolmogorov existence theorem}

\begin{definition}
	Let $E$ be a Polish space (homeomorphic to a separable complete metric space.)
	Let $\mathcal{E} = \mathcal{B}(E)$ be a Borel $\sigma-$field of $E$. (Think of $E$ as $\mathbb{R}$, $\mathbb{R}^d$, separable Hilbert space $L^p$ with $1 \leq p < \infty$ etc.)
	
	Consider a arbitrary index set $I$. For each finite tuple $( i_1, \ldots, i_k )$ of $I$, we associate it with a probability measure $\mu_{( i_1,\ldots,i_k)}$ on $( \underbrace{E \times \ldots \times E}_\text{k times}, \, \mathcal{E}_{i_1} \otimes \ldots \otimes \mathcal{E}_{i_k})$ where $\mathcal{E}_{i_j}$ is a $\sigma-$field on $E$ for $j=1,\ldots,k$. Then the family of probability measures $\left\{ \mu_{(i_1,\ldots,i_k)} \right\}$ indexed by the finite tuples of $I$ is said to be consistent if
	\begin{enumerate}
		\item for each $\{ i_1, \ldots, i_k\}\subseteq I $ and each permutation $\pi$ of $\{i_1,\ldots,i_k\}$, we have
		$$
			\mu_{(i_1,\ldots,i_k)} =\mu_{(\pi(i_1), \ldots, \pi(i_k) )} \circ \varphi_\pi^{-1}
		$$
		where
		$
			\varphi_\pi(x_{\pi(i_1)}, \ldots, x_{\pi(i_k)}) = (x_{i_1}, \ldots, x_{i_k}).
		$
		\item for each $\{i_1, \ldots, i_k, i_{k+1} \} \subset I$, for any $A \in \underbrace{\mathcal{E} \otimes \ldots \otimes \mathcal{E}}_\text{k times}$,
		$$
			\mu_{( i_1,\ldots,i_k)}(A) = \mu_{(i_1,\ldots, i_k, i_{k+1})}(A \times E).
		$$
	\end{enumerate} 
\end{definition}

\begin{theorem}[Kolmogorov existence theorem]
	Consider the space $(\Omega, \mathcal{F})$, where $\Omega = E^I$ is the product of copies of $E$ or set of functions from $I$ into $E$, and $\mathcal{F} = \mathcal{E}^I$ with $\mathcal{E}^I = \bigotimes_{i \in I} \mathcal{E}_i$ is the product $\sigma-$field (generated by the cylinders with finite base). If the family of probability measures $\underline{\mu} = \{ \mu_{(i_1,\ldots i_k)} \}$ indexed by finite tuples of $I$ is consistent, then there exists a probability measure $\mathbb{P}_{\underline{\mu}}$ on $(\Omega, \mathcal{F})$ such that for every $i\in I$ and every $\omega \in \Omega$, if we set 
	$$X^i(\omega) = \omega(i)$$
	as a random variable valued in $(E, \mathcal{E}_i)$, then for every $\{i_1, \ldots, i_k\} \subseteq I$ we have
	$$
		\mathcal{L}_{\mathbb{P}_{\underline{\mu}}}(X^{i_1}, \ldots, X^{i_k}) = \mu_{(i_1, \ldots, i_k)}.
	$$
	where $\mathcal{L}_{\mathbb{P}_{\underline{\mu}}}$ is the marginal distribution of $P_{\underline{\mu}}$ on $(\underbrace{ E\times \ldots,\times E}_\text{k times}, \mathcal{E}_{i_1} \otimes \ldots \otimes \mathcal{E}_{i_k})$.
	
\end{theorem}

\begin{definition}
	The random variable $X^i$ for every $i \in I$, viewed as a function from $\Omega$ to $E$, is called the $i-$coordinate projection function.
\end{definition}


\begin{remark}
	Given a set of \textit{consistent} finite dimensional probability distributions over an arbitrary index set $I$, ONE CAN ALWAYS construct a probability space $(\Omega, \mathcal{F},\mathbb{P})$ and a process $(X^i)_{i \in I}$ such that the finite dimensional marginals of $\mathbb{P}$ are the probabilities we started from.
\end{remark}

Examples:
\begin{itemize}
	\item Construction of the Brownian Motion.
	\item Construction of the Poisson process.
	\item White noise: $(X^i)_{i\in I}$ i.i.d with distribution $\mu \in \mathcal{P}(E)$.
\end{itemize}


\subsection{structure of product sigma field}
We want discuss a bit more about the structure of the product $\sigma$-field $\mathcal{E}^I = \bigotimes_{i \in I} \mathcal{E}_i$ with $\mathcal{E}_i = \mathcal{E}$ for all $i \in I$. 

Informally speaking, a sigma field generated by the cylinders with finite base has the following property: let $\Omega = E^I$ be a set of functions from $I$ to $E$, then for any finite subset $\{i_1,\ldots,i_k\}$ of $I$ and $A_{i_1}, \ldots, A_{i_k} \in \mathcal{E}$, we have 
$$
	\left\{\omega \in \Omega : \omega(i_j) \in A_{i_j}, \, j=1,\ldots,k \right\} \in \mathcal{E}^I.
$$

We start by clarifying some notations. 

\begin{definition}
For an arbitrary space $\Omega$, an arbitrary index set $A$, and a measurable space  $(E,\mathcal{E})$, let us denote by $\{X_\alpha\}_{\alpha \in A}$ the set of functions $X_\alpha : \Omega \to E$. We denote by $\mathcal{F} = \sigma\{X_\alpha: \alpha \in A\}$ the smallest sigma field on $\Omega$ for which $X_\alpha$ is $(\mathcal{F}, \mathcal{E})$ measurable for all $\alpha \in A$. In another words, for every $\alpha \in A$ and every $B\in \mathcal{E}$, 
$$
	(X_\alpha)^{-1}(B) \in \cF.
$$
\end{definition}


\begin{definition} Consider an arbitrary index set $I$ and a family of measurable spaces $(E_i, \mathcal{E}_i)$. Let us consider here a special case when $E_i = E$ and $\mathcal{E}_i = \mathcal{E}$ for a given measurable space $(E, \mathcal{E})$. 
	
The \textit{production space} is denoted by $\prod_{i\in I} E_i$, and it can be represented as a collection of all functions from $I$ into $E$, denoted by $E^I$. 
	
Consider a set of functions $(X^i)_{i\in I}$ where $X^i: E^I \to E$ is defined by 
$$
	X^i(\omega) = \omega(i),\qquad \forall \, \omega \in E^I.
$$
For every $i\in I$, the function is called \textit{$i-$coordinate projection function}.
 
\textit{A one-dimensional cylinder set} is the set of the form $\prod_{i \in I} B_i$ where there exists only one $i_0 \in I$ and one $B \in \mathcal{E}$ such that $B_{i_0} = B$ and $B_i = E$ for all $i \neq i_0$. 

We define the \textit{product $\sigma-$field}, denoted by $\bigotimes_{i \in I}\mathcal{E}_i$ or $\mathcal{E}^I$, as the one generated by all the one-dimensional cylinder sets.
\end{definition}

\begin{lemma}
The product $\sigma-$field $\bigotimes_{i \in I} \mathcal{E}_i$ is the minimal $\sigma-$field on $E^I$ that makes coordinate projection function $X_i$ measurable for all $i \in I$. Namely
$$
	\mathcal{E}^I = \bigotimes_{i\in I} \mathcal{E} = \sigma\{ X^i:  i \in I \}.
$$
\end{lemma}

\begin{lemma}
	Let $(\Omega, \mathcal{F})$ be a measurable space and $I$ be an arbitrary index set. Let $(E,\mathcal{E})$ be a measurable space. Let $(Y^i)_{i \in I}$ be a family of functions from $\Omega$ into $E$. We define $\xi : \Omega \ni \omega \mapsto \xi(\omega) \in E^I$ such that
	$$
	\xi(\omega)(i) = Y^i(\omega).
	$$
	Then $\xi$ is $(\mathcal{F},\mathcal{E}^I)$-measurable if and only if $Y^i$ is $(\mathcal{F}, \mathcal{E})-$measurable.
\end{lemma}

\begin{theorem}
	Let $\Omega$ be an arbitrary set and let $I$ be an arbitrary index set. Let $(E,\mathcal{E})$ be a measurable space. Let $(Y^i)_{i \in I}$ be a family of functions from $\Omega$ into $E$. Then we have the following two properties:
	\begin{enumerate}
		\item For every $A \in \sigma\{ Y^i: i\in I \}$ and every $\omega \in A$, if there is another $\omega' \in \Omega$ satisfying
		$$
			Y^i(\omega) = Y^i(\omega'), \qquad \forall \, i \in I,
		$$
		then $\omega' \in A$.
		\item For any $A \in \sigma\{Y^i: i \in I \}$, there exists a subset $J\subset I$ such that $J$ is at most countable and 
		$$
			A \in \sigma\{ Y^j: j \in J \}.
		$$
	\end{enumerate}
\end{theorem}

\begin{proof}
	Let $\mathcal{F}= \sigma\{ Y^i, i \in I \}$ be the smallest $\sigma-$field on $\Omega$ that makes all $Y^i$ measurable. We define $\xi : \Omega \ni \omega \mapsto \xi(\omega) \in E^I$ such that
	$$
	\xi(\omega)(i) = Y^i(\omega).
	$$
 	Then $\xi$ is $(\cF, \cE^I)$ measurable. So $\mathcal{F}$ contains $\{\xi^{-1}(A): A \in \mathcal{E}^I\}$ and in fact they are equal.
	
	\begin{enumerate}
		\item 
		For every $A \in \mathcal{F}$ and every $\omega \in A$, if $\omega' \in \Omega$ such that
		$$
			Y^i(\omega) = Y^i(\omega'), \qquad \forall i \in I.
		$$
		Then $\xi(\omega) = \xi(\omega')$, so that $\omega' \in A$.
		\item the claim means that 
		$$ \mathcal{F}= \sigma\{Y^i: i \in I\} = \bigcup_{J \subseteq I, J \text{ countable}} \sigma\{Y^j: j \in J\} =: \mathcal{G}.$$
		It is obvious that $\mathcal{G} \subseteq \mathcal{F}$. To have the other inclusion, we will show that $\mathcal{G}$ is indeed a $\sigma-$field. The only non-trivial thing is to show the countable union property. Let $(A_n)_{n \in \mathbb{N}}$ be a countable sequence of elements in $\cG$, then there exists a sequence of countable subsets of $I$, denoted by $(J_n)_{n\in \mathbb{N}}$, such that for every $n\in \mathbb{N}$  $A_n \in \sigma\{Y^j: j \in J_n\}$. Let $J = \cup_{n} J_n$, then $J$ is also a countable subset of $I$. Moreover, for all $n \in \mathbb{N}$, 
		$$
			A_n \in \sigma\{Y^j, j\in J_n\}  \subseteq \sigma\{Y^j: j \in J\}.
		$$
		Since $\sigma\{Y^j: j \in J\}$ is a $\sigma-$field, we deduce that
		$$
			\bigcup_n A_n \in \sigma\{ Y^j:  j \in J \} \subseteq \mathcal{G}.
		$$
	\end{enumerate}
\end{proof}


\subsection{Doob lemma}

Let $(I, \mathcal{I}, \lambda)$ is a probability space. Let $E$ be a polish space and $\mu \in \mathcal{P}(E)$ be a probability measure on a Borel $\sigma-$field of $E$. 

Kolmogorov says that (even if $I$ is only a set) for the space $(\Omega, \mathcal{F}) = (E^I \, , \bigotimes_{i \in I} \mathcal{B}(E) )$, there exists a probability measure $\mathcal{P}_\mu$ on $(\Omega, \mathcal{F})$ such that
if we define $X^i$ for $i \in I$ as coordinate projection, namely 
\begin{equation*}
	\begin{array}{rrcl}
			X^i : & \Omega &\longrightarrow & E\\
				  &	\omega &\mapsto  &\omega(i)
	\end{array}
\end{equation*}
then $X^i$ is $(\mathcal{F}, \mathcal{B}(E))$-measurable, the push forward distribution of $X^i$ is $$
\mathcal{L}(X^i) = \mathbb{P_\mu} \circ (X^i)^{-1} = \mu,
$$ 
and $(X^i)_{i \in I}$ are independent (i.e. any finite subset $X^{i_1}, \ldots, X^{i_k}$ are independent).

We denote by $\mathbb{P}= \mathbb{P}_\mu$ in the following.\\

 
Now I want to think of $I$ as part of $(I,\mathcal{I}, \lambda)$. The following lemma, due to Doob (1953 or 1963), indicates the inadequacy of the product $\sigma-$filed $\mathcal{F}$. We recalled that $\mathcal{F}$ is generated by the cylinders.

\begin{lemma}
	Assume that $I=[0,1]$ and $(E,\mathcal{E}) = (\mathbb{R}, \cB(\mathbb{R}))$. Consider a function $h: [0,1] \to E$ and the set 
	$$
		\mathfrak{M}_h = \{ \omega \in \Omega:  X^{i}(\omega)= h(i) \text{ except for at most countably many }  i\in I \}.
	$$
	Then $\mathfrak{M}_h$ has outer measure $1$.
\end{lemma}

\begin{proof}
	Let $A \in \mathcal{F} = \bigotimes_{[0,1]} \mathcal{B}(E)$. Then $A$ is determined by a countable subsets $I_A \subseteq I$ in the sense that if $\omega \in \Omega$ and $\omega' \in \Omega$ satisfying $\omega(i) = \omega'(i)$ for all $i \in I_A$, then $\omega \in A$ if and only if $\omega' \in A$.
	
	Now suppose that $\mathfrak{M}_h \subset A$, and pick any $\omega \in \Omega$, we construct $\omega' \in \Omega$ such that
	$$
	\omega'(i) = 
	\left\{
		\begin{array}{cc}
			\omega(i) & i \in I_A \\
			h(i) & i \notin I_A
		\end{array}
	\right.
	$$
	Since $\omega'(i) = h(i)$ except for countably many $i \in I$, then we have $\omega' \in \mathfrak{M}_h$. Since $\mathfrak{M}_h \subset A$, so that $\omega' \in A$. Moreover, we know that $\omega'(i) = \omega(i)$ for all $i \in I_A$, then $\omega \in A$ from the property of the $\sigma-$field $\mathcal{F}$. This means that $A = \Omega$. Hence, the outer measure of $\mathfrak{M}_h$ takes the value
	$$
		\mathbb{P}^*(\mathfrak{M}_h) = \inf_{\mathfrak{M}_h \subseteq A} \mathbb{P}(A) = \mathbb{P}(\Omega) = 1.
	$$
\end{proof}

\begin{remark}
	\begin{itemize}
		\item Space of continuous functions $\mathcal{C}^0 = \mathcal{C}(I;E)$ is not in $\mathcal{F}$.
		\item A set $A \subseteq \Omega$ cannot belongs to $\mathcal{F}$ unless there exists a countable set $I_A \subset I$ such that for any $\omega, \omega' \in \Omega$ satisfying $\omega(i) = \omega'(i)$ for all $i \in I_A$ implies the property that $\omega \in A$ if and only if $\omega' \in A$.
		\item set of sample paths of Poisson process are not in $\mathcal{F}$.
	\end{itemize}
\end{remark}

	
\begin{remark}
	Assume that $I=[0,1]$ and $\mathcal{I}=\mathcal{B}(I)$ and $\lambda$ is the Lebesgue measure on $[0,1]$.
	\begin{itemize}
		\item Let $h:[0,1] \to \mathbb{R}$ be non-Lebesgue measurable (no measurable function equals to $h$ $\lambda-$almost everywhere), then all the elements of $\mathfrak{M}_h$ are non-Lebesgue measurable. 
		
		If $\mathcal{N}$ represents the set of non-Lebesgue measurable functions, then
		$$
			\mathbb{P}^*(\cN) = 1
		$$
		so that 
		$$
			\mathbb{P}_*(\cN^c) = 0
		$$
		where $\cN^c$ is the set of Lebesgue measurable functions.
		\item Let $h:[0,1] \to \mathbb{R}$ be a Lebesgue measurable function, then all elements of $\mathfrak{M}_h$ are Lebesgue measurable, so that
		$$
			\mathbb{P}^*(\mathcal{N}^c) = 1.
		$$
	\end{itemize}
	Thus, $\mathcal{N}^c$ is not $\mathbb{P}-$measurable.
\end{remark}


\subsection[Games with a Continuum of Players]{\textbf{Games with a Continuum of Players}[cf. Carmona section 3.7]}
\label{se:continuum}

The rationale for the mean field game models studied in this book is based on the limit as $N\to\infty$ of $N$-player games with mean field interactions. One of the justifications given in Chapter 1 for the formulation of the mean field game paradigm is that the influence on the game of each individual player vanishes in this limit. Mathematical physicists and economists have been using game models in which the impact of each single player is \emph{insignificant}. They do just that by considering games for which the players are labelled by elements $i$ of an uncountable set $I$, accounting for a continuum of agents. This set $I$ is equipped with a $\sigma$-field $\cI$ and a probability measure $\lambda$ which is assumed to be continuous (i.e. non-atomic). In this way, if $i\in I$ represents a player, the fact that $\lambda(\{i\})=0$ accounts for the insignificance of the players in the model. This section is thus intended to be a quick introduction to the framework of games with a continuum of players.

\vskip 4pt
The classical Glivenko-Cantelli form of the Law of Large Numbers (LLN) states that if $F$ denotes the cumulative distribution function of a probability measure on $\RR$, if $(X^n)_{n\ge 1}$ is an infinite sequence of independent identically distributed random variables on a probability space $(\Omega,\cF,\PP)$ with common distribution $\mu$, 
and if we use the notation: 
\begin{equation}
\label{fo:GK}
F_\omega(x)=\limsup_{N\to\infty}\frac1N\#\bigl\{n \in \{1,\cdots,N\}  :  X^n(\omega)\le x\bigr\}, \quad x \in \RR, \ \omega \in \Omega,
\end{equation}
for the proportion of $X^n(\omega)$'s not greater than $x$, then this $\limsup$ is in fact a limit for all $x\in\RR$ and $\PP$-almost all $\omega\in\Omega$, and 
$\PP[\{\omega\in\Omega  :  F_\omega(\cdot)=F\}]=1$.

\vskip 2pt
Switching gears momentarily, recall that,
over fifty years ago, economists suggested that the appropriate model for perfectly competitive markets is a model with a continuum of traders represented as elements of a measurable space. In such a set-up, the insignificance of individual traders is captured by the idea of a set with zero measure, and summation or aggregation is generalized by the notion of integral. In games with a continuum of players, the latter are labelled by the elements $i\in I$ of an arbitrary set $I$ (often assumed to be uncountable, and most often chosen to be the unit interval $[0,1]$) equipped with a $\sigma$-field $\cI$ and a probability measure $\lambda$. In this set-up, if the state of each player $i\in I$ is given by a random variable $X^i$ on a probability space $(\Omega,\cF,\PP)$, in analogy with the countable case leading to formula \eqref{fo:GK}, the quantity:
\begin{equation}
\label{fo:empirical}
F_\omega(x)=\lambda\bigl(\{i\in I : X^i(\omega)\le x\}\bigr)
\end{equation} 
appears as a natural generalization of the \emph{proportion of $(X^i(\omega))_{i \in I}$'s not greater than $x$}, in other words of the cumulative distribution function of the empirical distribution, and if the 
$(X^i)_{i \in I}$'s were to be independent with the same distribution, we could have a reasonable generalization of the Law of Large Numbers to this setting. However, as we explain in the next subsection, measurability issues get in the way and such a generalization is, when it does exist, far from trivial.

\subsection[The Exact Law of Large Numbers]{\textbf{The Exact Law of Large Numbers}}

If $E$ is a Polish space, for each probability measure $\mu\in\cP(E)$, Kolmogorov's theorem can be used to construct on the product space $\Omega=E^I$ equipped with the $\sigma$-field $\cF$ obtained as the  product of copies of the Borel $\sigma$-field of $E$, the product probability measure $\PP$ for which the coordinate projections $(X^i:\Omega\ni\omega\mapsto X^i(\omega)=\omega(i)\in E)_{i \in I}$ become independent and identically distributed random variables with common distribution $\mu$ on the probability space $(\Omega,\cF,\PP)$. It is also well known that the sample paths $I \ni i\mapsto X^i(\omega) \in E$ are pretty rough functions since they are (for $\PP$-almost $\omega\in\Omega$) nowhere continuous and not even measurable.

Hence, this construction of a continuum of independent identically distributed random variables leads to irregular structures lacking measurability properties. The following definition offers an alternative which keeps most of what is needed from the independence. 

\begin{definition}
	\label{de:essentially_iid}
	If $E$ is a Polish space, the $E$-valued random variables $(X^i)_{i\in I}$ are said to be essentially pairwise independent if, for $\lambda$-almost every $i\in I$, the random variable $X^i$ is independent of $X^j$ for $\lambda$-almost every $j\in I$. Accordingly, if the real valued random variables $(X^i)_{i \in I}$ are square integrable, we say that the family $(X^i)_{i\in I}$ is essentially pairwise uncorrelated if, for $\lambda$-almost every $i\in I$, the correlation coefficient of $X^i$ with $X^j$ is $0$ for $\lambda$-almost every $j\in I$.
\end{definition}

One may wonder if  essentially pairwise independent families $(X^i)_{i\in I}$ can be constructed on probability spaces $(\Omega,\cF,\PP)$ so that the process $\bX:I\times\Omega\ni(i,\omega)\mapsto X^i(\omega)$ 
satisfies relevant measurability properties. 
To do so, we shall construct such processes on extensions of the product space $(I\times \Omega,\cI\otimes\cF,\lambda\otimes\PP)$, which are called Fubini's extensions. \index[sub]{Fubini extension}\index[sub]{extension!Fubini}

\begin{definition}
	\label{de:Fubini_extension}
	If $\cI\boxtimes\cF$ is a $\sigma$-field containing $\cI\otimes\cF$
	and $\lambda\boxtimes\PP$ is a probability measure on 
	$(I\times\Omega,\cI\boxtimes\cF)$, then $(I\times\Omega,\cI\boxtimes\cF,\lambda\boxtimes\PP)$ is said to be a Fubini extension of $(I\times\Omega,\cI\otimes\cF,\lambda\otimes\PP)$ if, for every measurable and $\lambda\boxtimes\PP$-integrable 
	$X:I\times\Omega\ni(i,x)\mapsto X^i(\omega)\in\RR$, we have:
	\begin{enumerate}
		\itemsep=2pt
		\item for $\lambda$-a.e. $i\in I$, $\Omega \ni \omega \mapsto 
		X^i(\omega)$ is a $\PP$-integrable random variable, and for $\PP$-a.e. $\omega\in \Omega$, $I \ni i \mapsto X^i (\omega)$ is measurable and $\lambda$-integrable;
		\item $I\ni i\mapsto\int_\Omega X^i(\omega)d\PP(\omega)$ is measurable and $\lambda$-integrable, and $\Omega\ni \omega\mapsto\int_I X^i(\omega)d\lambda(i)$ is a $\PP$-integrable random variable, and:
		\begin{equation}
		\label{fo:Fubini}
		\begin{split}
		\int_I\biggl(\int_\Omega X^i(\omega)d\PP(\omega)\biggr)d\lambda(i)&=\int_\Omega\biggl(\int_IX^i(\omega)d\lambda(i)\biggr)d\PP(\omega)
		\\
		&=\int_{I\times\Omega} X^i(\omega)d \bigl( \lambda\boxtimes \PP\bigr) (i,\omega).
		\end{split}
		\end{equation} 
	\end{enumerate}
\end{definition}

In the sequel, we shall use the standard symbol $\EE$ for denoting the expectation under the sole probability $\PP$. 
\vskip 4pt


Measurable essentially pairwise independent processes
$\bX$ are first constructed in such a way that, for each $i\in I$, the law of $X^i$ is the uniform distribution on the unit interval $[0,1]$.
Then, using the tools we develop in Chapter \ref{ch:measures}, see for example Lemma \ref{le:skorohod},  we easily construct  measurable essentially pairwise independent Euclidean-valued processes with any given prescribed marginals. So the actual problem is to construct rich product probability spaces in the sense of the following definition.

\begin{definition}
	\label{de:rich}
	A Fubini extension $(I\times\Omega,\cI\boxtimes\cF,\lambda\boxtimes\PP)$  is said to be rich 
	if there exists a real valued $\cI\boxtimes\cF$-measurable essentially pairwise independent process $\bX$ such that the law of $X^i$ is the uniform distribution on $[0,1]$ for every $i\in I$.
\end{definition} 

We refer to the Notes \& Complements at the end of the chapter for references to papers giving the construction of essentially pairwise independent measurable processes on Fubini extensions. 

The following gives a simple property of rich Fubini extensions.

\begin{lemma}
	\label{le:rich}
	If the Fubini extension $(I\times\Omega,\cI\boxtimes\cF,\lambda\boxtimes\PP)$ is rich, then $\lambda$ is necessarily atomless.
\end{lemma}

\proof{We shall argue by contradiction. 
	If $A\in\cI$, with $\lambda(A)>0$, is an atom of $(I,\cI,\lambda)$, then, for $\PP$-a.e. $\omega\in\Omega$, the function $I \ni i \mapsto X^i(\omega)$ is
	$\lambda$-a.e. constant on $A$. So for $\PP$-a.e. $\omega\in\Omega$ and $\lambda$-a.e. $i\in A$, 
	$$
	X^i(\omega)=\int_AX^j(\omega)\frac{d\lambda(j)}{\lambda(A)},
	$$
	and using the Fubini property \eqref{fo:Fubini}, we deduce that for $\lambda$-a.e. $i\in A$, the random variable $\Omega\ni\omega \mapsto X^i(\omega)$ is 
	$\PP$-a.e. equal to the random variable $\theta : 
	\Omega \ni \omega
	\mapsto
	\int_AX^j(\omega) d\lambda(j)/\lambda(A)$.
	Also, for any event $B \in \cF$,
	\begin{equation*}
	\begin{split}
	\PP [ \theta \in B] &= \lambda \boxtimes 
	\PP \bigl[ (i,\omega) \in I \times \Omega : X^i(\omega) \in B \bigr]
	\\
	&= \int_{I} \PP [ X^i \in B ] d\lambda(i) = \textrm{\rm Leb}_{1}(B),
	\end{split}
	\end{equation*} 
	proving that $\theta$, as a random variable on $(\Omega,\cF,\PP)$, has the uniform distribution. 
	In particular, $\EE[\theta^2]= 1/3$. 
	
	On the other hand, we know that, for almost every $i \in I$, 
	the function $I \times \Omega \ni (j,\omega) \mapsto X^i(\omega) 
	X^j(\omega)$ is $\cI \boxtimes \cF$-measurable. Also, by 
	the Fubini property,
	the function $I \ni j \mapsto \EE[X^i X^j]$ is integrable 
	with respect to $\lambda$ and 
	\begin{equation}
	\label{eq:ch:mfg:LLN:exact:1}
	\int_{I} \EE[X^i X^j] d\lambda(j) = \EE[X^i \theta]. 
	\end{equation} 
	Now, we observe that the function $I \times \Omega \ni (i,\omega) \mapsto 
	X^i(\omega) \theta(\omega)$ is also $\cI \boxtimes \cF$-measurable. 
	Hence, $I \ni i \mapsto \EE[X^i \theta]$ is integrable with respect to 
	$\lambda$ and 
	\begin{equation*}
	\int_{I} \EE[X^i \theta] d\lambda(i) = \EE[\theta^2] = \frac13. 
	\end{equation*}
	The contradiction comes from the fact that, for almost every
	$i \in I$, $X^i$ is independent to $X^j$ for almost every $j \in I$. In other words,
	the left-hand side in 
	\eqref{eq:ch:mfg:LLN:exact:1}
	is equal to: 
	\begin{equation*}
	\int_{I} \EE[X^i X^j] d\lambda(j) = \frac{1}{\lambda{A}} \int_A \mathbb{E}[X^i] \mathbb{E}[X^j] d\lambda(j) = \frac{1}{4},
	\end{equation*}
	which gives the desired contradiction. 
}

Using Lemma 5.29 from Chapter 5 
when $E$ is a Euclidean space and an extension of it when $E$ is a more general Polish space, see for instance the Notes \& Complements 
at the end of Chapter 5, 
we get the following result which we already announced.\\

We recall the following lemma
\begin{lemma}[see lemma 5.29]
	Let $E$ be a Polish space, $\exists \varphi: [0,1] \times \mathcal{P}(E) \to E$ measurable such that $\forall \nu \in \mathcal{P}(E)$ 
	$$
		Leb \circ \psi(\cdot, \nu)^{-1} = \nu.
	$$
\end{lemma}


\begin{proposition}
	\label{pr:rich_white_noise}
	If the Fubini extension $(I\times\Omega,\cI\boxtimes\cF,\lambda\boxtimes\PP)$ is rich,
	if $E$ is a Polish space, and if $\mu:I\mapsto\cP(E)$ is $\cI$-measurable, then there exists a $\cI\boxtimes\cF$-measurable $E$-valued essentially pairwise independent process $\bY:I\times\Omega\mapsto E$ such that for $\lambda$-a.e. $i\in I$, $\PP\circ Y_i^{-1}=\mu_i$.
\end{proposition}


\begin{proof}
	Define 
	$ Y(i,\omega)= \psi(X^i(\omega), \mu_i)$ where $X = (X^i)_{i\in I}$ is an essential white noise whit distribution uniform $[0,1]$. For $i \in I$ fixed, the mapping $\omega \mapsto X^i(\omega)	$
	has a uniform distribution on $[0,1]$, i.e. $\mathcal{L}(X^i) = Leb([0,1])$.
	And $\psi(\cdot, \mu_i)$ takes the uniform distribution on $[0,1]$  into $\mu_i$. 
	
	Since for $\lambda-$a.e. $i \in I$, $X^i$ is independent of $X^j$ for $\lambda-$a.e. $j \in I$, so that for $\lambda-$a.e. $i \in I$, $\psi(X^i, \mu_i)$ is independent of $\psi(X^j, \mu_j)$ for $\lambda-$a.e. $j \in I$. 
	
	Done. 
\end{proof}

An exact law of large numbers can be proven  on Fubini's extensions. In a weak form, this law can be given in the following wasy.

\begin{theorem}
	\label{th:exact_LLN}
	Let $\bX=(X^i)_{i\in I}$ be a measurable square integrable process on a Fubini extension $(I\times\Omega,\cI\boxtimes\cF,\lambda\boxtimes\PP)$. The following are equivalent:
	\vskip 1pt
	(i) The random variable $(X^i)_{i\in I}$ are essentially pairwise uncorrelated;
	\vskip 1pt
	(ii) For every $A\in\cI$ with $\lambda(A)>0$, one has for $\PP$-almost surely in $\omega\in\Omega$:
	$$
	\int_AX^i(\omega) d\lambda(i)=\int_A\EE[X^i] d\lambda(i).
	$$
\end{theorem}
\begin{proof}
	\emph{First Step:}
	We first check that if $\bY=(Y^i)_{i\in I}$ and  $\bZ=(Z^i)_{i\in I}$ are measurable and square integrable processes on the Fubini extension
	$(I\times\Omega,\cI\boxtimes\cF,\lambda\boxtimes\PP)$, and if we set
	$\tilde{X}^{i,j}(\omega)=Y^i(\omega)Z^j(\omega)$ for $i,j\in I$ and $\omega\in\Omega$, then $\Omega \ni \omega \mapsto \tilde{X}^{i,j}$ is $\PP$-integrable for $\lambda$-a.e. $i\in I$ and $j\in I$.
	Now, 
	proceeding as in the proof of Lemma 
	\ref{le:rich}
	and
	using the Fubini property of the space, we easily check that, for $\lambda$-a.e. $i\in I$, the function $I \ni j\mapsto \EE[ \tilde{X}^{i,j}]$ is $\lambda$-integrable, that the function
	$I\ni i\mapsto \int_I
	\EE[ \tilde{X}^{i,j}]d\lambda(j) = \EE [Y^i \int_{I} Z^{j} d\lambda(j)]$ is $\lambda$-integrable, that
	the function 
	$\Omega\ni \omega\mapsto 
	(\int_I Y^i(\omega)d\lambda(i))(\int_I Z^j(\omega)d\lambda(j))
	$
	is $\PP$-integrable and that:
	\begin{equation}
	\label{fo:fs}
	\EE\biggl[\biggl(\int_I Y^i(\omega)d\lambda(i)\biggr)\biggl(\int_I Z^j(\omega)d\lambda(j)\biggr)\biggr]
	=\int_I\biggl(\int_I\EE[ \tilde{X}^{i,j}]d\lambda(i)\biggr)d\lambda(j).
	\end{equation}
	
	
	\vskip 2pt\noindent
	\emph{Second Step: }
	Let $A,B\in \cI$, and let us define the processes $\bY=(Y^i)_{i\in I}$ and  $\bZ=(Z^i)_{i\in I}$  by 
	$(Y^i={\mathbf 1}_A(i)(X^i-\EE[X^i]))_{i \in I}$ and 
	$(Z^i={\mathbf 1}_B(i)(X^i-\EE[X^i]))_{i \in I}$ respectively. Applying \eqref{fo:fs} from the first step we get:
	\begin{equation}
	\label{fo:(3)}
	\begin{split}
	&\int_A\int_B\EE\Bigl[\Bigl(X^i-\EE[X^i]\Bigr)\Bigl(X^j-\EE[X^j]\Bigr)\Bigr]d\lambda(i)d\lambda(j)\\
	&\hskip 75pt
	=\EE\biggl[\int_A\Bigl(X^i-\EE[X^i]\Bigr)d\lambda(i)\int_B\Bigl(X^j-\EE[X^j]\Bigr) d\lambda(j)\biggr],
	\end{split}
	\end{equation}
	and the implication 
	\textit{(i})
	$\Rightarrow$ 
	\textit{(ii})
	follows by taking $B=A$. On the other hand, if we assume that \textit{(ii)} holds, equation \eqref{fo:(3)} implies that:
	$$
	\int_A\int_B\EE\Bigl[\Bigl(X^i-\EE[X^i]\Bigr)\Bigl(X^j-\EE[X^j]\Bigr)\Bigr]d\lambda(i)d\lambda(j)=0
	$$
	for all $A,B\in \cI$. The set $A\in \cI$ being arbitrary, we conclude that: 
	$$
	\int_B\EE\Bigl[\Bigl(X^i-\EE[X^i]\Bigr)\Bigl(X^j-\EE[X^j]\Bigr)\Bigr]d\lambda(j)=0,
	$$
	for $\lambda$-a.e. $i\in I$.  So for $\lambda$-a.e. $i\in I$, $B\in\cI$ being arbitrary, we conclude that: 
	$$
	\EE\Bigl[\Bigl(X^i-\EE[X^i]\Bigr)\Bigl(X^j-\EE[X^j]\Bigr)\Bigr]=0
	$$ 
	for $\lambda$-a.e. $j\in I$ which completes the proof.
\end{proof}
\vskip 2pt

Theorem \ref{th:exact_LLN} provides a form of the weak law of large numbers for essentially pairwise uncorrelated uncountable families of random variables. Here is a stronger form for 
essentially pairwise independent families of random variables.

\begin{theorem}
	\label{re:exact_LLN}
	Let $E$ be a Polish space and $\bX=(X^i)_{i\in I}$ be a measurable
	$E$-valued process on a Fubini extension $(I\times\Omega,\cI\boxtimes\cF,\lambda\boxtimes\PP)$
	such that the random variables $(X^i)_{i\in I}$ are essentially pairwise independent. Then, for $\PP$ almost every $\omega \in \Omega$ and for any $B$ in the Borel $\sigma$-field $\cB(E)$, 
	\begin{equation*}
	\lambda \bigl[ \{ i \in I : X^i(\omega) \in B \} \bigr] 
	= \int_{I}
	\PP \bigl[ X^i \in B\bigr] d \lambda (i).
	\end{equation*}
\end{theorem}

Of course, we may choose $E$ as a Euclidean space, in which case we get a strong form of the exact law of large numbers for essentially pairwise independent families of random variables with values in $\RR^d$, for some $d \geq 1$. By choosing $E$ as a functional space, the same holds true for a continuum of essentially pairwise independent random processes.

Finally, we can also derive conditional versions of these exact laws. We do not give the details here because we want to keep the presentation to a rather non-technical level since our motivation is merely to connect our approach to mean field games to the existing literature on games with a continuum of players. The interested reader is referred to the Notes \& Complements at the end of the chapter for references.


\subsection{Question}

Question: Can the product probability space $(\Omega, \mathcal{F}, \mathbb{P}_\mu)$ be a component of a Fubini extension?

\begin{proposition}
	There is no atomless probability space $(I, \mathcal{I}, \lambda)$ satisfying
	\begin{itemize}
		\item $(I \times \Omega, \cI \boxtimes \cF, \lambda \boxtimes \PP )$ is a Fubini extension with marginals $(I, \cI, \lambda)$ and $(\Omega, \cF, \PP)$.
		\item $(X^i)_{i \in I}$ is $\cI \boxtimes \cF$ measurable.
	\end{itemize}
\end{proposition}

\begin{proof}
	Suppose such a Fubini extension exists. Take $E = \mathbb{R}$. Let $B$ be an interval in $E$ and $\mu(B) < 1$. Let $c \in B$ and we define two functions $h: I \ni i \mapsto h(i) = c \in E$ and $g = \mathbbm{1}_B \circ X : I \times \Omega \to E$, namely for every $(i,\omega) \in I \times \Omega$,
	$$
		g(i,\omega) = 
		\left\{
		\begin{array}{cl}
			1 & if \quad X^{i}(\omega) \in B \\
			0 & o.w.
		\end{array}
		\right.
	$$
	Then, $g$ is bounded and $\cI \boxtimes \cF$ measurable, $(g(i,\cdot))_{i\in I}$ are independent.
	
	By the exact law of large number,
	$$
		\lambda \circ g^{-1}_\omega = (\lambda \boxtimes \PP) \circ g^{-1}
	$$
	for $\PP$-almost every $\omega \in \Omega$, where $g_\omega = g(\cdot, \omega)$ for $\omega \in \Omega$.
	
	Applied thus to the whole space $E = \mathbb{R}$, we get
	$$
		\lambda(g_\omega^{-1}(E)) =  (\lambda \boxtimes \PP)(g^{-1}(E))
	$$
	or equivalently
	$$
		\lambda(\{i\in I: g(i,\omega) \in B \}) = \int \lambda(di) \PP(d\omega)g(i,\omega) = \int \lambda(di) \mu(B) = \mu(B) < 1.
	$$
	So for $\PP$-a.e. $\omega \in \Omega$, $X^{\cdot}(\omega) = \omega(\cdot) \notin \mathfrak{M}_h$. This is because if $\omega \in \Omega$ such that $X^i(\omega) = h(i) = c$, then 
	$X^i(\omega) \in B$. If that were to happen except for countably many $i$, then $\lambda-$measure of those $i$'s would be $1$ since $\lambda$ is atomless.
	
	Hence $\mathbb{P}(\mathfrak{M}_h) = 0$. Contradiction.	
\end{proof}



